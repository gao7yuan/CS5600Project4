+-------------------------+
|      CS 5600           |
| PROJECT 4: FILE SYSTEMS |
|     DESIGN DOCUMENT     |
+-------------------------+


---- GROUP ----


>> Fill in the names and email addresses of your group members.

Yuan Gao <gao.yuan4@husky.neu.edu>
Zhenhui Guo <guo.zhenhui@husky.neu.edu>
Anthony Meisen <meisen.a@husky.neu.edu>

---- PRELIMINARIES ----


>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.


>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.


INDEXED AND EXTENSIBLE FILES
============================


---- DATA STRUCTURES ----


>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
#define NUM_DIRECT_BLOCKS 122 /* Number of direct blocks in a sector. */
#define NUM_INDIRECT_BLOCK_POINTERS 128 /* Number of blocks in an indirect inode block sector. */


/* On-disk inode.
   Must be exactly BLOCK_SECTOR_SIZE bytes long. */
struct inode_disk {
  block_sector_t direct_blocks[NUM_DIRECT_BLOCKS]; /* 122 direct pointers. */
  block_sector_t indirect_block;        /* 1 single indirect pointer. */
  block_sector_t double_indirect_block; /* 1 double indirect pointer. */


  bool is_dir;           /* True for directory, false for file */
  off_t length;          /* File size in bytes. */
  unsigned magic;        /* Magic number. */
  block_sector_t parent; /* The parent of this inode */
};


/* Indirect inode. */
struct indirect_inode_block_sector {
  block_sector_t blocks[NUM_INDIRECT_BLOCK_POINTERS]; /* 128 pointers. */
};


/* In-memory inode. */
struct inode {
  struct list_elem elem;  /* Element in inode list. */
  block_sector_t sector;  /* Sector number of disk location. */
  int open_cnt;           /* Number of openers. */
  bool removed;           /* True if deleted, false otherwise. */
  int deny_write_cnt;     /* 0: writes ok, >0: deny writes. */
  struct inode_disk data; /* Inode content. */
  struct lock lock;       /* Inode lock. */
  off_t readable_length;  /* Readable file size. */
  block_sector_t parent;  /* Sector number of parent location*/
  bool is_dir; /* true: this inode is a dir, false: this inode is a file*/
};


>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.
Direct blocks = 122 sector * 512 bytes/sector 
          = 62464 bytes
Single indirect block = 1 indirect_block * 128 sector/indirect_block * 512 bytes/sector 
          = 65536 bytes
Double indirect block = 1 double_indirect_block * 128 indirect_block/double_indirect_block 
* 128 sector/indirect_block * 512 bytes/sector
           = 8388608 bytes
Total = 8516608 bytes ~= 8.12 MB


---- SYNCHRONIZATION ----


>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.
Each inode has a lock. An inode lock is being used when extending a file. The process that does not hold the lock will sleep until it has acquired the lock before it can attempt to extend the file.


>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.
Update to inode->readable_length is done once B has finished writing during an extension. If A tries to read before B writes, A will not see any data that B writes beyond EOF. If A tries to read after B is done writing, A will see all the extension data written by B.


>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.
Reading does not require inode lock. Only extending a file during a write requires a lock. So, reading and writing do not block each other.


---- RATIONALE ----


>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?
Inode structure is a multilevel index. The direct blocks and 1 single indirect block can only support smaller files. The double indirect block is required to support a file size of 8 MB. A total of 122 direct blocks is implemented to make use of all available space of 512 bytes in a block sector.


SUBDIRECTORIES
==============


---- DATA STRUCTURES ----


>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


The change of data structures is included in the “Indexed and Extensible Files” part. Basically, I added two fields in both inode and inode_disk:
* bool is_dir      /* True if this inode is a directory, false if this is a file. */
* block_sector_t parent  /* The sector number of the parent of this inode. */


---- ALGORITHMS ----


>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?


The user-specified path should be separated by ‘/’. If the specified path starts with ‘/’, then it means the path starts with the root directory. If not, it means it starts with the current thread’s running directory. 
We can traverse the user-specified path by step by step parsing each directory in the path. And there are two cases:
* If the specified path is an absolute path, we can just traverse all the way down, until we reach the destination or we find any directory on the path that does not exist.
* If the specified path contains a relative path, we can traverse all the way down until we meet special characters ‘.’ and ‘..’. 
   * If a ‘.’ is met, it means the current directory, we can keep traverse down; 
   * If a ‘..’ is met, it means the parent directory, we open its parent directory for traversal. If the parent directory does not exist, we return NULL.


---- SYNCHRONIZATION ----


>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.
We can prevent races with locking: we add a lock to each inode to make sure for a given directory, any directory operation can only be performed by a single thread at a time


>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?
No. When a directory is opened by a process or is in use as a process’s current working directory, the in_use variable will be marked as true. When a directory is being removed, its in_use variable will be marked as false. Therefore A directory which is in use will not be removed.


---- RATIONALE ----


>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.
I am using the a struct *dir to represent the current directory of a process. This struct contains two fields: a pointer to the inode of this directory, and an offset of this directory. They are necessary fields for us to do some important operations on the dir. For example: we need the parent sector in inode to get the parent of this directory, we need to call inode_write_at when we add a file name to a dir, we need offset when we call inode_read_at. 


BUFFER CACHE
============


---- DATA STRUCTURES ----


>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


struct cache *fs_cache; /* Cache for the file system. */
struct block *fs_device; /* Device for the file system. */




/**
  * A cache of file blocks. Formed by a list of cache entries.
  */
struct cache {
   struct list cache_entry_list; /* A list of cache_entry. */
   uint32_t cache_size; /* Size of cache in sectors. */
};


/**
  * A cache entry, one cache block corresponds to one sector on disk.
  */
struct cache_entry {
   struct list_elem elem; /* Element in cache list. */
   uint8_t data[BLOCK_SECTOR_SIZE]; /* Data cached from disk. */
   block_sector_t sector; /* Sector number on disk. */
   bool dirty; /* Whether data has been written. */
   bool accessed; /* Whether data has been accessed. */
   int open_cnt; /* Number of openers of this cache entry / sector. */
   struct lock cache_entry_lock; /* Lock for cache entry. */
};


---- ALGORITHMS ----


>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.


1. The cache blocks are maintained in a list. We check each cache block or cache entry one by one. 
2. If a cache entry has at least one opener, we don’t evict it.
3. If a cache entry does not have any opener, we check if it has been accessed.
4. If yes, we change accessed boolean to false, and move on to the next cache entry.
5. Otherwise, we plan to evict this cache entry that has not been accessed recently.
6. Before we evict it, we need to check the dirty boolean of this cache entry.
7. If dirty is true, we need to write the content on this cache block to its corresponding sector on disk.
8. After that, we can evict this cache entry.


>> C3: Describe your implementation of write-behind.


* We create a thread to periodically write dirty cache entries to disk.
* When writing cache to disk, we check the cache entries one by one for its dirty boolean. If dirty is true, we write the content on the cache entry to its corresponding sector on disk, and then mark dirty as false. Otherwise, we move on to the next cache entry.


>> C4: Describe your implementation of read-ahead.


* We create a thread to enable read ahead.
* When we read content from a sector on disk (which might already be on cache), meanwhile we create this thread to fetch data for the next sector on disk, just in case we are going to read it next.
* We check whether this next sector has already been cached. If not, we find an available position in cache and read the content of that sector from disk to cache.


---- SYNCHRONIZATION ----


>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?


* We keep track of the number of openers for each cache block. If the number of openers is greater than zero, then we choose not to evict this block. We also make sure that a lock for the cache block is needed when updating the opener count for the cache block.


>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?


* A lock can be added to the cache block that is about to be evicted, so that other processes need to wait for this lock to be released before they access the block.


---- RATIONALE ----


>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.


* Reading data from cache, which is on the memory, would be much faster than reading data from disk. If a sector of disk is frequently read, by using a cache, we can reduce workload a lot.
* If a process is reading a large file, by applying read-ahead, when reading one sector, the next sector is being cached as well. Therefore, when the process tries to read the next sector, it just needs to fetch the content from cache instead of from disk, which would reduce workload.
* Writing to cache is faster than writing to disk. If many writes happen to a sector, by implementing write-behind, we only update the data on cache. Only when we are about to evict this cache block, we write all dirty data to disk, thus saving a lot of workload. Since we are concerned about loss of data in case of power outage, we also periodically write dirty data from cache to disk.